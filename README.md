# Neural Network From Scratch with Visualizations

This repository showcases a simple neural network regression model built entirely from scratch using NumPy. It walks through key stages including:

- Data generation and feature engineering
- Manual implementation of a feedforward neural network
- Training using batch gradient descent with momentum and regularization (L1 & L2)
- Hyperparameter tuning using a grid search
- Evaluation using MSE, MAE, RMSE
- Visualization of performance and training metrics

## ğŸ“Š Visualizations

The project includes detailed plots such as:
- Scatter plots of input vs target
- Target distribution
- Feature correlation heatmap
- Training vs validation loss curves
- Validation loss across configurations

## ğŸ“ Project Structure

â”œâ”€â”€ notebook.ipynb # Main Jupyter Notebook with code and outputs
â”œâ”€â”€ plots/ # Folder containing all generated plot images
â”œâ”€â”€ README.md # Project overview and documentation


## âš™ï¸ Technologies Used

- Python (NumPy, Pandas, Matplotlib, Seaborn)
- Jupyter Notebook
- Scikit-learn (for data splitting only)

## ğŸ§  Why This Project?

This project was developed as part of a hands-on deep learning exploration to better understand:
- How neural networks function internally
- How hyperparameters affect training
- How to debug numerical instabilities like NaNs and overflows

## ğŸ”¬ Author

Mohammed Saad Alshutwi â€” [Senior Computer Science - KSU]
