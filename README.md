# Neural Network From Scratch with Visualizations

This repository showcases a simple neural network regression model built entirely from scratch using NumPy. It walks through key stages including:

- Data generation and feature engineering
- Manual implementation of a feedforward neural network
- Training using batch gradient descent with momentum and regularization (L1 & L2)
- Hyperparameter tuning using a grid search
- Evaluation using MSE, MAE, RMSE
- Visualization of performance and training metrics

## 📊 Visualizations

The project includes detailed plots such as:
- Scatter plots of input vs target
- Target distribution
- Feature correlation heatmap
- Training vs validation loss curves
- Validation loss across configurations

## 📁 Project Structure

├── notebook.ipynb # Main Jupyter Notebook with code and outputs
├── plots/ # Folder containing all generated plot images
├── README.md # Project overview and documentation


## ⚙️ Technologies Used

- Python (NumPy, Pandas, Matplotlib, Seaborn)
- Jupyter Notebook
- Scikit-learn (for data splitting only)

## 🧠 Why This Project?

This project was developed as part of a hands-on deep learning exploration to better understand:
- How neural networks function internally
- How hyperparameters affect training
- How to debug numerical instabilities like NaNs and overflows

## 🔬 Author

Mohammed Saad Alshutwi — [Senior Computer Science - KSU]
